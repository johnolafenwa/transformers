# Introduction

With a bit on introduction and history out of the way, we shall focus the rest of this book exclusively on explaining the different types of transformer models, how the transformer architecture works and their applications to natural language processing, computer vision, speech and a couple of other problems we solve with deep learning. In order to understand well enough how transformers work, a basic understanding of NLP is very helpful, hence, in the next couple of chapters we shall touch a bit on NLP topics such as text tokenization.

Broadly, transformer models are of 3 types.

\-          Transformer Encoder

\-          Transformer Decoder

\-          Transformer Encoder Decoder

Note, transformer models used in computer vision do not always confirm to this categorization, but this is a special case we shall discuss in a dedicated chapter, for now, we shall focus on distilling each of the above three types of transformer models.

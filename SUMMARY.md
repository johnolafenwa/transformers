# Table of contents

* [Deep Learning with Transformers](README.md)
* [Paradigms of Deep Learning Research](paradigms-of-deep-learning-research.md)
* [Sequence Modelling with Transformer Encoder](sequence-modelling-with-transformer-encoder.md)
* [Sequence Generation with Transformer Decoder](sequence-generation-with-transformer-decoder.md)
* [Sequence to Sequence Generation with Transformer Encoder Decoder](sequence-to-sequence-generation-with-transformer-encoder-decoder.md)
* [Self Supervised Pretraining of Transformers](self-supervised-pretraining-of-transformers.md)
* [Speeding Up Transformers](speeding-up-transformers.md)
* [Case Studies of Transformer Models](case-studies-of-transformer-models/README.md)
  * [GPT](case-studies-of-transformer-models/gpt.md)
  * [BERT](case-studies-of-transformer-models/bert.md)
* [Finetuning Large Language Models](finetuning-large-language-models/README.md)
  * [Transfer Learning](finetuning-large-language-models/transfer-learning.md)
  * [Reinforcement Learning from Human Feedback (RLHF)](finetuning-large-language-models/reinforcement-learning-from-human-feedback-rlhf.md)
* [Vision Transformers](vision-transformers.md)
* [Speech Transformers](speech-transformers.md)
